arrange(desc(n))
# Rating distribution
ratings %>%
ggplot(aes(x = rating)) +
geom_histogram(binwidth = 0.5)
# Most active users
ratings %>%
count(userId) %>%
arrange(desc(n)) %>%
head(10)
# Most rated movies
top_movies <- ratings %>%
count(movieId) %>%
arrange(desc(n)) %>%
head(20) %>%
left_join(movies, by = "movieId")
top_movies
# Top rated movies (with at least 100 ratings)
ratings %>%
group_by(movieId) %>%
summarise(avg_rating = mean(rating),
n_ratings = n()) %>%
filter(n_ratings >= 100) %>%
arrange(desc(avg_rating)) %>%
head(20) %>%
left_join(movies, by = "movieId")
# Most common tags
tags %>%
count(tag) %>%
arrange(desc(n)) %>%
head(20)
# Load necessary libraries
library(tidyverse)
library(skimr)  # For summary statistics
# Load the datasets
movies <- read_csv("data/movies.csv")
ratings <- read_csv("data/ratings.csv")
tags <- read_csv("data/tags.csv")
links <- read_csv("data/links.csv")
# Basic dimensions
cat("Movies dataset:", dim(movies), "\n")
cat("Ratings dataset:", dim(ratings), "\n")
cat("Tags dataset:", dim(tags), "\n")
cat("Links dataset:", dim(links), "\n")
# View structure of each dataset
str(movies)
str(ratings)
str(tags)
str(links)
# Check for missing values
colSums(is.na(movies))
colSums(is.na(ratings))
colSums(is.na(tags))
colSums(is.na(links))
# Basic summaries
summary(movies)
summary(ratings)
summary(tags)
summary(links)
# More detailed summaries with skimr
skim(movies)
skim(ratings)
skim(tags)
skim(links)
# Process movies dataset - extract year
movies <- movies %>%
mutate(year = str_extract(title, "\\(\\d{4}\\)$"),
year = as.numeric(str_extract(year, "\\d{4}")),
title_clean = str_remove(title, " \\(\\d{4}\\)$"))
# Movie distribution by decade
movies %>%
mutate(decade = floor(year/10)*10) %>%
count(decade) %>%
arrange(decade)
# Genre distribution
movies %>%
mutate(genres = strsplit(as.character(genres), "\\|")) %>%
unnest(genres) %>%
count(genres) %>%
arrange(desc(n))
# Rating distribution
ratings %>%
ggplot(aes(x = rating)) +
geom_histogram(binwidth = 0.5)
# Most active users
ratings %>%
count(userId) %>%
arrange(desc(n)) %>%
head(10)
# Most rated movies
top_movies <- ratings %>%
count(movieId) %>%
arrange(desc(n)) %>%
head(20) %>%
left_join(movies, by = "movieId")
top_movies
# Top rated movies (with at least 100 ratings)
ratings %>%
group_by(movieId) %>%
summarise(avg_rating = mean(rating),
n_ratings = n()) %>%
filter(n_ratings >= 100) %>%
arrange(desc(avg_rating)) %>%
head(20) %>%
left_join(movies, by = "movieId")
# Most common tags
tags %>%
count(tag) %>%
arrange(desc(n)) %>%
head(20)
# Load necessary libraries
library(tidyverse)
library(Matrix)      # For sparse matrices
library(recommenderlab)  # For recommendation algorithms
# Load the processed data from exploration phase
# Assuming you've saved the processed data or run the exploration script
# Handle missing values
movies_clean <- movies %>%
filter(!is.na(year)) %>%
filter(genres != "(no genres listed)")
# Filter out users and movies with too few ratings
min_ratings_user <- 5   # Minimum ratings per user
min_ratings_movie <- 5  # Minimum ratings per movie
# Find users and movies meeting minimum criteria
active_users <- ratings %>%
count(userId) %>%
filter(n >= min_ratings_user) %>%
pull(userId)
popular_movies <- ratings %>%
count(movieId) %>%
filter(n >= min_ratings_movie) %>%
pull(movieId)
# Filter ratings
ratings_filtered <- ratings %>%
filter(userId %in% active_users,
movieId %in% popular_movies)
# Create user-item matrix for collaborative filtering
ratings_matrix <- ratings_filtered %>%
select(userId, movieId, rating) %>%
spread(movieId, rating)
# Convert to matrix format
matrix_for_recommender <- as.matrix(ratings_matrix[,-1])
rownames(matrix_for_recommender) <- ratings_matrix$userId
# Convert to recommenderlab format
r_matrix <- as(matrix_for_recommender, "realRatingMatrix")
# Create movie features for content-based filtering
# Extract genres into one-hot encoding
genres_list <- movies %>%
mutate(genres = strsplit(as.character(genres), "\\|")) %>%
unnest(genres) %>%
distinct(genres) %>%
pull(genres)
# Create genre matrix
genre_matrix <- matrix(0,
nrow = nrow(movies_clean),
ncol = length(genres_list),
dimnames = list(movies_clean$movieId, genres_list))
# Fill genre matrix
for (i in 1:nrow(movies_clean)) {
movie_genres <- unlist(strsplit(as.character(movies_clean$genres[i]), "\\|"))
genre_idx <- which(genres_list %in% movie_genres)
genre_matrix[i, genre_idx] <- 1
}
# Create train-test split
set.seed(123)
evaluation_scheme <- evaluationScheme(r_matrix,
method = "split",
train = 0.8,
given = 5,  # Number of items to use for prediction
goodRating = 3.5)  # Threshold for "good" rating
# Save prepared data for modeling
save(movies_clean, ratings_filtered, r_matrix, genre_matrix, evaluation_scheme,
file = "data/prepared_data.RData")
# Load the RData file if you've already saved it
load("data/prepared_data.RData")
# Create a directory for CSV files if it doesn't exist
dir.create("data/csv_exports", showWarnings = FALSE)
# 1. Export cleaned movies data
write.csv(movies_clean, "data/csv_exports/movies_clean.csv", row.names = FALSE)
# 2. Export filtered ratings data
write.csv(ratings_filtered, "data/csv_exports/ratings_filtered.csv", row.names = FALSE)
# 3. Export genre matrix
# Convert to data frame and add movie ID column
genre_matrix_df <- as.data.frame(genre_matrix)
genre_matrix_df$movieId <- rownames(genre_matrix)
write.csv(genre_matrix_df, "data/csv_exports/genre_matrix.csv", row.names = FALSE)
# 4. Export user-item matrix
# This can be challenging due to its sparse nature
# Convert from recommenderlab format to regular matrix
ratings_matrix_full <- as(r_matrix, "matrix")
# Convert to data frame
ratings_df <- as.data.frame(ratings_matrix_full)
# Add user IDs as a column
ratings_df$userId <- rownames(ratings_matrix_full)
# Export (note: this might be a very large file)
write.csv(ratings_df, "data/csv_exports/ratings_matrix.csv", row.names = FALSE)
# Alternatively, export a long-format version which is more efficient
# Convert from wide to long format
ratings_long <- as(r_matrix, "data.frame")
write.csv(ratings_long, "data/csv_exports/ratings_long.csv", row.names = FALSE)
# 5. Export train-test split information
train_set <- getData(evaluation_scheme, "train")
train_df <- as(train_set, "data.frame")
write.csv(train_df, "data/csv_exports/train_set.csv", row.names = FALSE)
test_set <- getData(evaluation_scheme, "known")
test_df <- as(test_set, "data.frame")
write.csv(test_df, "data/csv_exports/test_set.csv", row.names = FALSE)
library(recommenderlab)
library(tidyverse)
# Load prepared data
load("data/prepared_data.RData")  # Contains r_matrix (the rating matrix)
# Create a user-based recommender model
ubcf_model <- Recommender(r_matrix, method = "UBCF",
parameter = list(
nn = 30,  # Number of nearest neighbors
method = "cosine",  # Similarity measure
normalize = "center"  # Center the ratings by subtracting user mean
))
# Generate recommendations for a sample user
sample_user_id <- sample(rownames(r_matrix), 1)  # Random user
n_recommendations <- 10  # Number of recommendations to generate
# Get recommendations
ubcf_predictions <- predict(ubcf_model, r_matrix[sample_user_id,], n = n_recommendations)
ubcf_recommendations <- as(ubcf_predictions, "list")
# Display recommendations with movie titles
ubcf_rec_items <- ubcf_recommendations[[1]]
ubcf_rec_movies <- movies_clean %>%
filter(movieId %in% ubcf_rec_items) %>%
select(movieId, title, genres)
print(ubcf_rec_movies)
# Create an item-based recommender model
ibcf_model <- Recommender(r_matrix, method = "IBCF",
parameter = list(
k = 30,  # Number of similar items
method = "cosine"  # Similarity measure
))
library(recommenderlab)
library(tidyverse)
# Load prepared data
load("data/prepared_data.RData")  # Contains r_matrix (the rating matrix)
# Create a user-based recommender model
ubcf_model <- Recommender(r_matrix, method = "UBCF",
parameter = list(
nn = 30,  # Number of nearest neighbors
method = "cosine",  # Similarity measure
normalize = "center"  # Center the ratings by subtracting user mean
))
# Generate recommendations for a sample user
sample_user_id <- sample(rownames(r_matrix), 1)  # Random user
n_recommendations <- 10  # Number of recommendations to generate
# Get recommendations
ubcf_predictions <- predict(ubcf_model, r_matrix[sample_user_id,], n = n_recommendations)
ubcf_recommendations <- as(ubcf_predictions, "list")
# Display recommendations with movie titles
ubcf_rec_items <- ubcf_recommendations[[1]]
ubcf_rec_movies <- movies_clean %>%
filter(movieId %in% ubcf_rec_items) %>%
select(movieId, title, genres)
print(ubcf_rec_movies)
library(recommenderlab)
library(tidyverse)
# Load prepared data
load("data/prepared_data.RData")  # Contains r_matrix (the rating matrix)
# Create a user-based recommender model
ubcf_model <- Recommender(r_matrix, method = "UBCF",
parameter = list(
nn = 30,  # Number of nearest neighbors
method = "cosine",  # Similarity measure
normalize = "center"  # Center the ratings by subtracting user mean
))
# Generate recommendations for a sample user
sample_user_id <- sample(rownames(r_matrix), 1)  # Random user
n_recommendations <- 10  # Number of recommendations to generate
# Get recommendations
ubcf_predictions <- predict(ubcf_model, r_matrix[sample_user_id,], n = n_recommendations)
ubcf_recommendations <- as(ubcf_predictions, "list")
# Display recommendations with movie titles
ubcf_rec_items <- ubcf_recommendations[[1]]
ubcf_rec_movies <- movies_clean %>%
filter(movieId %in% ubcf_rec_items) %>%
select(movieId, title, genres)
print(ubcf_rec_movies)
library(recommenderlab)
library(tidyverse)
# Load your prepared data
# This should contain your ratings matrix in recommenderlab format
load("data/prepared_data.RData")
# Create a user-based collaborative filtering model
ubcf_model <- Recommender(r_matrix, method = "UBCF",
parameter = list(
nn = 30,  # Number of nearest neighbors
method = "cosine",  # Similarity measure (options: cosine, pearson, jaccard)
normalize = "center"  # Center the ratings by subtracting user mean
))
# Save the model for later use
saveRDS(ubcf_model, "models/ubcf_model.rds")
library(recommenderlab)
library(tidyverse)
# Load your prepared data
# This should contain your ratings matrix in recommenderlab format
load("data/prepared_data.RData")
# Create a user-based collaborative filtering model
ubcf_model <- Recommender(r_matrix, method = "UBCF",
parameter = list(
nn = 30,  # Number of nearest neighbors
method = "cosine",  # Similarity measure (options: cosine, pearson, jaccard)
normalize = "center"  # Center the ratings by subtracting user mean
))
# Save the model for later use
saveRDS(ubcf_model, "models/ubcf_model.rds")
library(recommenderlab)
library(tidyverse)
# Load your prepared data
# This should contain your ratings matrix in recommenderlab format
load("data/prepared_data.RData")
# Create a user-based collaborative filtering model
ubcf_model <- Recommender(r_matrix, method = "UBCF",
parameter = list(
nn = 30,  # Number of nearest neighbors
method = "cosine",  # Similarity measure (options: cosine, pearson, jaccard)
normalize = "center"  # Center the ratings by subtracting user mean
))
# Save the model for later use
saveRDS(ubcf_model, "models/ubcf_model.rds")
# Create a user-based collaborative filtering model
ubcf_model <- Recommender(r_matrix, method = "UBCF",
parameter = list(
nn = 30,  # Number of nearest neighbors
method = "cosine",  # Similarity measure (options: cosine, pearson, jaccard)
normalize = "center"  # Center the ratings by subtracting user mean
))
# Save the model for later use
saveRDS(ubcf_model, "models/ubcf_model.rds")
# Pick a random user to test
sample_user_id <- sample(rownames(r_matrix), 1)
# Generate 10 recommendations for this user
n_recommendations <- 10
ubcf_predictions <- predict(ubcf_model, r_matrix[sample_user_id,], n = n_recommendations)
ubcf_recommendations <- as(ubcf_predictions, "list")
# Get the recommended movie IDs
ubcf_rec_items <- ubcf_recommendations[[1]]
# Join with movie data to show titles
ubcf_rec_movies <- movies_clean %>%
filter(movieId %in% ubcf_rec_items) %>%
select(movieId, title, genres)
# Display the recommendations
print(paste("Recommendations for user:", sample_user_id))
print(ubcf_rec_movies)
get_ubcf_recommendations <- function(user_id, model, movies_data, n = 10) {
# Check if user exists in the data
if(!(user_id %in% rownames(r_matrix))) {
return("User not found in dataset")
}
# Generate recommendations
pred <- predict(model, r_matrix[user_id,], n = n)
rec_list <- as(pred, "list")
rec_items <- rec_list[[1]]
# Get movie details
recommendations <- movies_data %>%
filter(movieId %in% rec_items) %>%
arrange(match(movieId, rec_items)) %>%
select(movieId, title, genres)
return(recommendations)
}
# Test the function
test_recs <- get_ubcf_recommendations("1", ubcf_model, movies_clean)
print(test_recs)
# Evaluate on your evaluation scheme
ubcf_eval <- evaluate(evaluation_scheme,
method = "UBCF",
parameter = list(nn = 30, method = "cosine"),
n = c(1, 5, 10, 15, 20))
# Plot ROC curve
plot(ubcf_eval, annotate = TRUE, main = "UBCF Performance")
# Calculate RMSE
ubcf_predictions <- predict(ubcf_model, getData(evaluation_scheme, "known"))
ubcf_rmse <- calcPredictionAccuracy(ubcf_predictions, getData(evaluation_scheme, "unknown"))
# Create a user-based collaborative filtering model
ubcf_model <- Recommender(r_matrix, method = "UBCF",
parameter = list(
nn = 30,  # Number of nearest neighbors
method = "cosine",  # Similarity measure (options: cosine, pearson, jaccard)
normalize = "center"  # Center the ratings by subtracting user mean
))
# Save the model for later use
saveRDS(ubcf_model, "models/ubcf_model.rds")
# Pick a random user to test
sample_user_id <- sample(rownames(r_matrix), 1)
# Generate 10 recommendations for this user
n_recommendations <- 10
ubcf_predictions <- predict(ubcf_model, r_matrix[sample_user_id,], n = n_recommendations)
ubcf_recommendations <- as(ubcf_predictions, "list")
# Get the recommended movie IDs
ubcf_rec_items <- ubcf_recommendations[[1]]
# Join with movie data to show titles
ubcf_rec_movies <- movies_clean %>%
filter(movieId %in% ubcf_rec_items) %>%
select(movieId, title, genres)
# Display the recommendations
print(paste("Recommendations for user:", sample_user_id))
print(ubcf_rec_movies)
get_ubcf_recommendations <- function(user_id, model, movies_data, n = 10) {
# Check if user exists in the data
if(!(user_id %in% rownames(r_matrix))) {
return("User not found in dataset")
}
# Generate recommendations
pred <- predict(model, r_matrix[user_id,], n = n)
rec_list <- as(pred, "list")
rec_items <- rec_list[[1]]
# Get movie details
recommendations <- movies_data %>%
filter(movieId %in% rec_items) %>%
arrange(match(movieId, rec_items)) %>%
select(movieId, title, genres)
return(recommendations)
}
# Test the function
test_recs <- get_ubcf_recommendations("1", ubcf_model, movies_clean)
print(test_recs)
# Evaluate on your evaluation scheme
ubcf_eval <- evaluate(evaluation_scheme,
method = "UBCF",
parameter = list(nn = 30, method = "cosine"),
n = c(1, 5, 10, 15, 20))
# Plot ROC curve
plot(ubcf_eval, annotate = TRUE, main = "UBCF Performance")
# Calculate RMSE
ubcf_predictions <- predict(ubcf_model, getData(evaluation_scheme, "known"))
ubcf_rmse <- calcPredictionAccuracy(ubcf_predictions, getData(evaluation_scheme, "unknown"))
# Load necessary libraries
library(tidyverse)
library(skimr)  # For summary statistics
# Load the datasets
movies <- read_csv("data/movies.csv")
ratings <- read_csv("data/ratings.csv")
tags <- read_csv("data/tags.csv")
links <- read_csv("data/links.csv")
# Basic dimensions
cat("Movies dataset:", dim(movies), "\n")
cat("Ratings dataset:", dim(ratings), "\n")
cat("Tags dataset:", dim(tags), "\n")
cat("Links dataset:", dim(links), "\n")
# View structure of each dataset
str(movies)
str(ratings)
str(tags)
str(links)
# Check for missing values
colSums(is.na(movies))
colSums(is.na(ratings))
colSums(is.na(tags))
colSums(is.na(links))
# Basic summaries
summary(movies)
summary(ratings)
summary(tags)
summary(links)
# More detailed summaries with skimr
skim(movies)
skim(ratings)
skim(tags)
skim(links)
# Process movies dataset - extract year
movies <- movies %>%
mutate(year = str_extract(title, "\\(\\d{4}\\)$"),
year = as.numeric(str_extract(year, "\\d{4}")),
title_clean = str_remove(title, " \\(\\d{4}\\)$"))
# Movie distribution by decade
movies %>%
mutate(decade = floor(year/10)*10) %>%
count(decade) %>%
arrange(decade)
# Genre distribution
movies %>%
mutate(genres = strsplit(as.character(genres), "\\|")) %>%
unnest(genres) %>%
count(genres) %>%
arrange(desc(n))
# Rating distribution
ratings %>%
ggplot(aes(x = rating)) +
geom_histogram(binwidth = 0.5)
# Most active users
ratings %>%
count(userId) %>%
arrange(desc(n)) %>%
head(10)
# Most rated movies
top_movies <- ratings %>%
count(movieId) %>%
arrange(desc(n)) %>%
head(20) %>%
left_join(movies, by = "movieId")
top_movies
# Top rated movies (with at least 100 ratings)
ratings %>%
group_by(movieId) %>%
summarise(avg_rating = mean(rating),
n_ratings = n()) %>%
filter(n_ratings >= 100) %>%
arrange(desc(avg_rating)) %>%
head(20) %>%
left_join(movies, by = "movieId")
# Most common tags
tags %>%
count(tag) %>%
arrange(desc(n)) %>%
head(20)
View(links)
View(movies)
View(movies_clean)
